
---

# ğŸ“Š å®éªŒç»“æœè§£é‡Š

### 1. RMSE vs é‡‡æ ·è½®æ•°

* **ä¸­æ–‡è§£é‡Š**ï¼šéšç€é‡‡æ ·è½®æ•°çš„å¢åŠ ï¼Œæ‰€æœ‰æ–¹æ³•çš„å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSEï¼‰éƒ½é€æ­¥ä¸‹é™ï¼Œè¯´æ˜å¢åŠ è§‚æµ‹ç‚¹ç¡®å®èƒ½æå‡æ¨¡å‹ç²¾åº¦ã€‚ä½†ä¸åŒé‡‡æ ·ç­–ç•¥çš„æ”¶æ•›é€Ÿåº¦å·®åˆ«æ˜¾è‘—ï¼šéšæœºé‡‡æ ·ä¸‹é™æœ€æ…¢ï¼›æ–¹å·®è´ªå¿ƒç­–ç•¥é›†ä¸­åœ¨é«˜ä¸ç¡®å®šæ€§åŒºåŸŸï¼Œæ”¶æ•›æ›´å¿«ï¼›A-optimal ç­–ç•¥ç»¼åˆè€ƒè™‘å…¨å±€ä¿¡æ¯ï¼Œä¸‹é™æœ€å¿«ï¼Œæœ€ç»ˆ RMSE æœ€ä½ã€‚
* **English**: As the sampling rounds increase, the root mean square error (RMSE) decreases across all methods, indicating that adding more observations improves model accuracy. However, the convergence speed differs significantly: random sampling is the slowest, variance-greedy sampling converges faster by targeting high-uncertainty regions, and A-optimal (mutual information based) achieves the fastest and lowest RMSE.

---

### 2. CRPS vs é‡‡æ ·è½®æ•°

* **ä¸­æ–‡è§£é‡Š**ï¼šCRPSï¼ˆè¿ç»­ç§©æ¦‚ç‡å¾—åˆ†ï¼‰è¡¡é‡çš„æ˜¯é¢„æµ‹åˆ†å¸ƒä¸çœŸå®å€¼çš„è´´åˆåº¦ã€‚æ›²çº¿æ˜¾ç¤ºï¼Œä¸»åŠ¨é‡‡æ ·ç­–ç•¥ä¸ä»…èƒ½é™ä½å‡å€¼é¢„æµ‹è¯¯å·®ï¼Œè¿˜èƒ½æå‡æ•´ä¸ªåˆ†å¸ƒçš„è´¨é‡ã€‚å…¶ä¸­ï¼ŒA-optimal ç­–ç•¥åœ¨ 10 è½®åè¾¾åˆ°æœ€ä½ CRPSï¼Œè¯´æ˜å…¶ä¸ç¡®å®šæ€§ä¼°è®¡æœ€å¯é ã€‚
* **English**: The Continuous Ranked Probability Score (CRPS) measures how well the predictive distribution matches the true values. The curves show that active sampling strategies improve not only mean prediction accuracy but also distribution quality. Among them, A-optimal achieves the lowest CRPS after 10 rounds, demonstrating the most reliable uncertainty estimation.

---

### 3. PIT æ ¡å‡†ç›´æ–¹å›¾

* **ä¸­æ–‡è§£é‡Š**ï¼šPIT åˆ†å¸ƒç”¨äºè¯„ä¼°é¢„æµ‹åˆ†å¸ƒçš„æ ¡å‡†æ€§ã€‚ç†æƒ³æƒ…å†µæ˜¯å‡åŒ€åˆ†å¸ƒï¼š

  * Baseline Kriging ç»“æœé›†ä¸­åœ¨ä¸­é—´ï¼Œè¯´æ˜æ¨¡å‹è¿‡äºè‡ªä¿¡ï¼Œä½ä¼°äº†ä¸ç¡®å®šæ€§ã€‚
  * Anisotropic GP æœ‰æ‰€æ”¹å–„ï¼Œä½†ä»å­˜åœ¨åå·®ã€‚
  * Co-Kriging æ¥è¿‘å‡åŒ€ï¼Œè¡¨æ˜åˆ†å¸ƒæ›´åˆç†ã€‚
  * Active Sampling å‡ ä¹å®Œå…¨å‡åŒ€ï¼Œè¯´æ˜æ¨¡å‹çš„æ¦‚ç‡é¢„æµ‹ä¸çœŸå®åˆ†å¸ƒé«˜åº¦ä¸€è‡´ï¼Œæ ¡å‡†æœ€ä½³ã€‚
* **English**: PIT histograms evaluate calibration of predictive distributions. Ideally, the values should follow a uniform distribution:

  * Baseline Kriging shows strong central bias, indicating overconfidence.
  * Anisotropic GP improves slightly but still shows deviation.
  * Co-Kriging is close to uniform, reflecting a more reasonable distribution.
  * Active Sampling is nearly uniform, meaning the predictive probabilities align very well with reality, showing the best calibration.

---

### 4. ç»“æœæ€»ç»“

* **ä¸­æ–‡æ€»ç»“**ï¼šç»¼åˆ RMSEã€CRPS ä¸ PIT ä¸‰ä¸ªæŒ‡æ ‡ï¼Œå¯ä»¥çœ‹åˆ°ä» Baseline â†’ Anisotropic â†’ Co-Kriging â†’ Active Samplingï¼Œæ¨¡å‹çš„ç²¾åº¦ã€åˆ†å¸ƒè´¨é‡å’Œæ ¡å‡†æ€§éƒ½é€æ­¥æå‡ã€‚å°¤å…¶æ˜¯ä¸»åŠ¨é‡‡æ ·æ˜¾è‘—åŠ é€Ÿäº†è¯¯å·®ä¸‹é™ï¼Œå¹¶æå‡äº†æ¨¡å‹çš„å¯é æ€§ã€‚
* **English Summary**: Combining RMSE, CRPS, and PIT results, we observe a clear progression: Baseline â†’ Anisotropic â†’ Co-Kriging â†’ Active Sampling. Accuracy, distribution quality, and calibration all improve step by step, with active sampling significantly accelerating error reduction and enhancing model reliability.

---
